{
 "metadata": {
  "name": "",
  "signature": "sha256:8cbc6733a3520606dc2f7ed7f99f6ccd3b19d6bd86467c50ff419936bfd02524"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Programming Assignment I: Exploratory Analysis over 2012 FEC Presidential Election Dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Team Details\n",
      "--------------\n",
      "\n",
      "When submitting, fill your team details in this cell. Note that this is a markdown cell.\n",
      "\n",
      "**Student 1 Name and ID:** Sumesh Nellemakkal Balan   UT ID: 1001119408\n",
      "\n",
      "**Student 2 Name and ID:** Sreehari Balakrishna Hegden, UTA ID: 1001109610\n",
      "\n",
      "**Student 3 Name and ID:** Divya Maria Jose , UTA ID : 1000989859"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Assignment Details\n",
      "-------------------\n",
      "\n",
      "In this assignment, you will be learn more about three key steps in a data analytics process. \n",
      "\n",
      "### 1. Data Collection\n",
      "\n",
      "In the first set of tasks, you will put to use the various techniques we learnt in web scraping and use it to scrape three popular websites. \n",
      "\n",
      "### 2. Exploratory Analysis\n",
      "In the second and third set of tasks, you will conduct a guided exploration over 2012 FEC Presidential Election Dataset. You will learn and use some of the most common exploration/aggregation/descriptive operations. This should also help you learn most of the key functionalities in Pandas.\n",
      "\n",
      "### 3. Visualization\n",
      "In the third set of tasks (that is done in conjunction with #2), you will also learn how to use visualization libraries to identify patterns in data that will help in your further data analysis. You will also explore most popular chart types and how to use different libraries and styles to make your visualizations more attractive.\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Python Packages\n",
      "\n",
      "Here are the set of packages that you will use extensively in this assignment. Do NOT import any new packages without confirming with the instructor. The objective is to make you identify and use the various functions in the packages imported below. Besides, to my knowledge, the libraries below do offer a concise way to achieve the homework tasks anyway."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# special IPython command to prepare the notebook for matplotlib\n",
      "%matplotlib inline \n",
      "\n",
      "#Array processing\n",
      "import numpy as np\n",
      "import seaborn as sb\n",
      "#Data analysis, wrangling and common exploratory operations\n",
      "import pandas as pd\n",
      "from pandas import Series, DataFrame\n",
      "\n",
      "#A sane way to get web data\n",
      "import requests\n",
      "\n",
      "#Packages for web scraping. No need to use both. Feel free to use one of them.\n",
      "#from pattern import web\n",
      "#from BeautifulSoup import BeautifulSoup\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "#For visualization. Matplotlib for basic viz and seaborn for more stylish figures + statistical figures not in MPL.\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "\n",
      "#For some of the date operations\n",
      "import datetime\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 133
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Part 1: Web Scraping\n",
      "----------------\n",
      "\n",
      "In the first series of tasks, we will seek to scrape information from diverse websites. To make your job easier, you can assume that you do not need to do any complex webdriver stuff. For each task, you will implement a function that accepts an url and produces output in the format that the question asks.\n",
      "\n",
      "NOTE: Make sure that you follow the input and output requirements. The assignment will be evaluated and graded automatically by a script. Any error will result in you getting a score of 0 for that task.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(5 points) Website 1: Wikipedia\n",
      "-----------------------\n",
      "\n",
      "In the first task, we will seek to parse contents from a table in a Wikipedia page. You will implement a function that accepts two parameters. The first is the url and the second is the name of the table. For example, if the url was http://en.wikipedia.org/wiki/List_of_Test_cricket_records and the table name was \"Team wins, losses and draws\", then you have to parse the first table. Your code must produce as an output a Pandas data frame where the columns have same name as the table ('Team',\t'First Test match',\t'Matches',\t'Won',\t'Lost',\t'Tied',\t'Drawn' and '% Won') in this example. \n",
      "\n",
      "Do NOT worry about the data format of the Pandas data frame. Simply treat each of them as a string.\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# coding: utf-8\n",
      "\n",
      "# In[ ]:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# In[2]:\n",
      "\n",
      "#Input:\n",
      "#    url: URL of a wikipedia page\n",
      "#    table_no: Number of the table to scrape\n",
      "#Output:\n",
      "#    df is a Pandas data frame that contains a tabular representation of the table\n",
      "#    The columns are named the same as the table columns\n",
      "#    Each row of df corresponds to a row in the table\n",
      "\n",
      "\n",
      "from bs4 import BeautifulSoup\n",
      "import urllib2\n",
      "from lxml.html import fromstring \n",
      "import re\n",
      "import csv\n",
      "import pandas as pd\n",
      "\n",
      "\n",
      "url= raw_input('Enter the URL')\n",
      "table_number= raw_input('Enter the table number')\n",
      "table_no=int(table_number)\n",
      "\n",
      "def scraping_wikipedia_table(url, table_no):\n",
      "    wiki=url\n",
      "    header = {'User-Agent': 'Mozilla/5.0'} #Needed to prevent 403 error on Wikipedia\n",
      "    req = urllib2.Request(wiki,headers=header)\n",
      "    page = urllib2.urlopen(req)\n",
      "\n",
      "    soup = BeautifulSoup(page)\n",
      "\n",
      "    table = soup.find_all('table')[table_no]\n",
      "\n",
      "    tmp = table.find_all('tr')\n",
      "\n",
      "    first = tmp[0]\n",
      "    allRows = tmp[1:-1]\n",
      "\n",
      "    headers = [header.get_text() for header in first.find_all('th')]\n",
      "    results = [[data.get_text() for data in row.find_all('td')] for row in allRows]\n",
      "\n",
      "    rowspan = []\n",
      "\n",
      "    for no, tr in enumerate(allRows):\n",
      "        tmp = []\n",
      "        for td_no, data in enumerate(tr.find_all('td')):\n",
      "            if data.has_key(\"rowspan\"):\n",
      "                rowspan.append((no, td_no, int(data[\"rowspan\"]), data.get_text()))\n",
      "\n",
      "\n",
      "    if rowspan:\n",
      "        for i in rowspan:\n",
      "            # tr value of rowspan in present in 1th place in results\n",
      "            for j in xrange(1, i[2]):\n",
      "                #- Add value in next tr.\n",
      "                results[i[0]+j].insert(i[1], i[3])\n",
      "\n",
      "\n",
      "    df = pd.DataFrame(data=results, columns=headers)\n",
      "    df\n",
      "\n",
      "    return df\n",
      "\n",
      "scraping_wikipedia_table(url, table_no)\n",
      "\n",
      "\n",
      "# In[ ]:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# In[ ]:\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[u'Innings and 579 runs'], [u'Innings and 360 runs'], [u'Innings and 336 runs'], [u'Innings and 332 runs'], [u'Innings and 324 runs']]\n",
        "Margin\tTeams\tVenue\tSeason\n",
        "\u00a0England (903-7 d) beat Australia (201 & 123)\tThe Oval, London\t1938\n",
        "\u00a0Australia (652\u20137 d) beat South Africa (159 & 133)\tNew Wanderers Stadium, Johannesburg\t2001\u201302\n",
        "\u00a0West Indies (614\u20135 d) beat India (124 & 154)\tEden Gardens, Kolkata\t1958\u201359\n",
        "\u00a0Australia (645) beat England (141 & 172)\tBrisbane Cricket Ground\t1946\u201347\n",
        "\u00a0Pakistan (643) beat New Zealand (73 & 246)\tGaddafi Stadium, Lahore\t2002\n",
        "\n",
        "Last updated: 10 January 2015[25]\n",
        "\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>                                            Margin</td>\n",
        "      <td>                               Teams</td>\n",
        "      <td>   Venue</td>\n",
        "      <td> Season</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>     \u00a0England (903-7 d) beat Australia (201 &amp; 123)</td>\n",
        "      <td>                    The Oval, London</td>\n",
        "      <td>    1938</td>\n",
        "      <td>   None</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> \u00a0Australia (652\u20137 d) beat South Africa (159 &amp; ...</td>\n",
        "      <td> New Wanderers Stadium, Johannesburg</td>\n",
        "      <td> 2001\u201302</td>\n",
        "      <td>   None</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>     \u00a0West Indies (614\u20135 d) beat India (124 &amp; 154)</td>\n",
        "      <td>               Eden Gardens, Kolkata</td>\n",
        "      <td> 1958\u201359</td>\n",
        "      <td>   None</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>         \u00a0Australia (645) beat England (141 &amp; 172)</td>\n",
        "      <td>             Brisbane Cricket Ground</td>\n",
        "      <td> 1946\u201347</td>\n",
        "      <td>   None</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td>       \u00a0Pakistan (643) beat New Zealand (73 &amp; 246)</td>\n",
        "      <td>             Gaddafi Stadium, Lahore</td>\n",
        "      <td>    2002</td>\n",
        "      <td>   None</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td>             \\nLast updated: 10 January 2015[25]\\n</td>\n",
        "      <td>                                None</td>\n",
        "      <td>    None</td>\n",
        "      <td>   None</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "                                                   0  \\\n",
        "0                                             Margin   \n",
        "1      \u00a0England (903-7 d) beat Australia (201 & 123)   \n",
        "2  \u00a0Australia (652\u20137 d) beat South Africa (159 & ...   \n",
        "3      \u00a0West Indies (614\u20135 d) beat India (124 & 154)   \n",
        "4          \u00a0Australia (645) beat England (141 & 172)   \n",
        "5        \u00a0Pakistan (643) beat New Zealand (73 & 246)   \n",
        "6              \\nLast updated: 10 January 2015[25]\\n   \n",
        "\n",
        "                                     1        2       3  \n",
        "0                                Teams    Venue  Season  \n",
        "1                     The Oval, London     1938    None  \n",
        "2  New Wanderers Stadium, Johannesburg  2001\u201302    None  \n",
        "3                Eden Gardens, Kolkata  1958\u201359    None  \n",
        "4              Brisbane Cricket Ground  1946\u201347    None  \n",
        "5              Gaddafi Stadium, Lahore     2002    None  \n",
        "6                                 None     None    None  "
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "### (5 points)  Website 2: Walmart\n",
      "\n",
      "In the second task, we will seek to scrape the results of Walmart. Specifically, we will focus on Movies department. Your job is to implement a function that accepts a valid search result url  (such as http://www.walmart.com/search/?query=marvel&cat_id=4096_530598 ), scrapes the 10-15 product listings in that url only and outputs a Pandas data frame with the following fields (with the EXACT names and data types as below): \n",
      "\n",
      "+ Product Title: String. Title of the product (such as Samsung Red WB1100F Smart Camera with 16.2 Megapixels and 35x Optical Zoom)\n",
      "+ Sale Price: Float. Price of the product (such as 249.99). This is the price that is highlighted in blue typically. Ignore the dollar sign and return the value only\n",
      "+ Number of Ratings: Integer. The number of ratings that users have provided for the product. This is the number associated with the star.\n",
      "+ Free Shipping: Boolean. Is True if the product has free shipping above $50 and false otherwise. \n",
      "+ Free Store Pickup: Boolean. Is True if the product has free store pickup and false otherwise. \n",
      "+ Starring: String. Contains the name of starring actors. Convert it to a simple string such as \"Chris Pratt Zoe Saldana Vin Diesel\" is okay. No need to parse it further.\n",
      "+ Running: Integer. The running time of the movie. Only the integer value is required (ie. NNNN minutes then return only NNNN).\n",
      "+ Format: String. Values such as Widescreen. Beware, some entries might not have this value.\n",
      "+ Rating: String. MPAA rating.\n",
      "\n",
      "Make sure that you observe the following:\n",
      "\n",
      "* If a data type is specified, then your data should be in that format. For eg, if a field is int, then ensure that it has an integer value.\n",
      "* Your code should not crash if some product did not have a valid value such as price. Instead you must fill it with NA (see Pandas tutorial for what NA is). "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# coding: utf-8\n",
      "\n",
      "# In[11]:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# In[2]:\n",
      "\n",
      "#Input:\n",
      "#    url: URL of a Walmart results page for a search query in Movies department\n",
      "#Output:\n",
      "#    df is a Pandas data frame that contains a tabular representation of the results\n",
      "#    The df must have 9 columns that must have the same name and data type as described above\n",
      "#    Each row of df corresponds to a movie in the results table\n",
      "\n",
      "\n",
      "from collections import defaultdict\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "import csv\n",
      "import pandas as pd\n",
      "\n",
      "\n",
      "\n",
      "url=raw_input('Enter the URL')\n",
      "\n",
      "def scraping_walmart_movies(url):\n",
      "   \n",
      "    r= requests.get(url)\n",
      "    r.content\n",
      "    soup = BeautifulSoup(r.content)\n",
      "\n",
      "\n",
      "    g_data = soup.find_all(\"div\", {\"class\" : \"tile-content\"})\n",
      "   \n",
      "\n",
      "    data=defaultdict(list)\n",
      "\n",
      "    #One loop to rule them all\n",
      "    for tile in g_data:\n",
      "        #the \"tile\" value in g_data contains what you are looking for...\n",
      "        #find the product titles\n",
      "        try:\n",
      "            title = tile.find(\"a\",\"js-product-title\")\n",
      "            data['Product Title'].append(title.text)\n",
      "        except:\n",
      "            data['Product Title'].append(\"NA\")\n",
      "\n",
      "        #find the prices\n",
      "        try:\n",
      "            price = tile.find('span', 'price price-display').text.strip()\n",
      "            data['Price'].append(price)\n",
      "        except:\n",
      "            data['Price'].append(\"NA\")\n",
      "\n",
      "        try:\n",
      "            g_star = tile.find(\"div\",{\"class\" : \"stars stars-small tile-row\"}).find('span','visuallyhidden').text.strip()\n",
      "            data['Stars'].append(g_star)\n",
      "        except:\n",
      "            data['Stars'].append(\"NA\")\n",
      "\n",
      "        try:\n",
      "            dd_starring = tile.find('dd', {\"class\" : \"media-details-multi-line media-details-artist-dd module\"}).text.strip()\n",
      "            data['Starring'].append(dd_starring)\n",
      "        except:\n",
      "            data['Starring'].append(\"NA\")\n",
      "\n",
      "        try:\n",
      "            running_time = tile.find('dt',{\"class\" : \"media-details-running-time\"})\n",
      "            run_time = running_time.find_next(\"dd\")\n",
      "            data['Running Time'].append(run_time.text)   \n",
      "        except:\n",
      "                    data['Running Time'].append(\"NA\")\n",
      "\n",
      "        try:\n",
      "            dd_format = tile.find('dt',{\"class\" :\"media-details-format\"})\n",
      "            form = dd_format.find_next(\"dd\")\n",
      "            data['Format'].append(form.text)\n",
      "        except:\n",
      "            data['Format'].append(\"NA\")\n",
      "\n",
      "        try:\n",
      "            dt_rating = tile.find('dt',{\"class\": \"media-details-rating\"})\n",
      "            rate = dt_rating.find_next(\"dd\")\n",
      "            data['Rating'].append(rate.text)\n",
      "        except:\n",
      "            data['Rating'].append(\"NA\")\n",
      "\n",
      "        div_shipping =tile.find('div',{\"class\":\"tile-aside-content\"}).text.strip()\n",
      "        check = \"Preorder now\"\n",
      "        if check in div_shipping:\n",
      "            data['Shipping'].append(\"True\")\n",
      "        else:\n",
      "            data['Shipping'].append(\"False\")\n",
      "\n",
      "        div_pickup =tile.find('div',{\"class\":\"tile-aside-content\"}).text.strip()\n",
      "        check = \"Preorder now\"\n",
      "        if check in div_shipping:\n",
      "            data['Store Pick Up'].append(\"True\")\n",
      "        else:\n",
      "            data['Store Pick Up'].append(\"False\")\n",
      "\n",
      "\n",
      "\n",
      "    df = pd.DataFrame(data)\n",
      "    df\n",
      "    \n",
      "    #print df\n",
      "\n",
      "    return df\n",
      "\n",
      "scraping_walmart_movies(url)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# In[5]:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# In[2]:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# In[ ]:\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5.0 stars\n",
        "5.0 stars\n",
        "4.5 stars\n",
        "5.0 stars\n",
        "4.5 stars\n",
        "5.0 stars\n",
        "4.0 stars\n",
        "5.0 stars\n",
        "4.5 stars\n",
        "4.5 stars\n",
        "5.0 stars\n",
        "4.5 stars\n",
        "5.0 stars\n",
        "5.0 stars\n",
        "4.5 stars\n",
        "5.0 stars\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Price</th>\n",
        "      <th>Product Title</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> $19.96</td>\n",
        "      <td>                Marvel's The Avengers (Widescreen)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> $33.98</td>\n",
        "      <td>                         Marvel Heroes: Collection</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td> $14.96</td>\n",
        "      <td>      Marvel: Guardians Of The Galaxy (Widescreen)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td> $13.47</td>\n",
        "      <td> Marvel Knights: Wolverine Versus Sabretooth - ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> $26.96</td>\n",
        "      <td>              Marvel Complete Giftset (Widescreen)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> $29.96</td>\n",
        "      <td> Marvel's The Avengers (DVD + Blu-ray) (Widescr...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td> $12.96</td>\n",
        "      <td>                         Spider-Man 2 (Widescreen)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td>  $6.99</td>\n",
        "      <td>          The Punisher (Extended Cut) (Widescreen)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> $13.47</td>\n",
        "      <td> Superheroes Collection: The Incredible Hulk Re...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> $19.96</td>\n",
        "      <td> Marvel: Iron Man &amp; Hulk - Heroes United (Wides...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> $18.75</td>\n",
        "      <td>  Captain America: The Winter Soldier (Widescreen)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> $19.96</td>\n",
        "      <td>      Iron Man 3 (DVD + Digital Copy) (Widescreen)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> $19.96</td>\n",
        "      <td>                 Thor: The Dark World (Widescreen)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td> $12.96</td>\n",
        "      <td> Spider-Man (2-Disc) (Special Edition) (Widescr...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td> $25.46</td>\n",
        "      <td> Spider-Man / Spider-Man 2 / Spider-Man 3 (Wide...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td>  $9.07</td>\n",
        "      <td> DC Showcase: Superman / Shazam!: The Return Of...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> $11.17</td>\n",
        "      <td>   Ultimate Avengers Movie Collection (Widescreen)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td>  $5.00</td>\n",
        "      <td> The Next Avengers: Heroes Of Tomorrow (Widescr...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td>  $5.48</td>\n",
        "      <td>         Ultimate Avengers: The Movie (Widescreen)</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td>  $9.57</td>\n",
        "      <td>    Ultimate Avengers 1 &amp; 2 (Blu-ray) (Widescreen)</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "     Price                                      Product Title\n",
        "0   $19.96                 Marvel's The Avengers (Widescreen)\n",
        "1   $33.98                          Marvel Heroes: Collection\n",
        "2   $14.96       Marvel: Guardians Of The Galaxy (Widescreen)\n",
        "3   $13.47  Marvel Knights: Wolverine Versus Sabretooth - ...\n",
        "4   $26.96               Marvel Complete Giftset (Widescreen)\n",
        "5   $29.96  Marvel's The Avengers (DVD + Blu-ray) (Widescr...\n",
        "6   $12.96                          Spider-Man 2 (Widescreen)\n",
        "7    $6.99           The Punisher (Extended Cut) (Widescreen)\n",
        "8   $13.47  Superheroes Collection: The Incredible Hulk Re...\n",
        "9   $19.96  Marvel: Iron Man & Hulk - Heroes United (Wides...\n",
        "10  $18.75   Captain America: The Winter Soldier (Widescreen)\n",
        "11  $19.96       Iron Man 3 (DVD + Digital Copy) (Widescreen)\n",
        "12  $19.96                  Thor: The Dark World (Widescreen)\n",
        "13  $12.96  Spider-Man (2-Disc) (Special Edition) (Widescr...\n",
        "14  $25.46  Spider-Man / Spider-Man 2 / Spider-Man 3 (Wide...\n",
        "15   $9.07  DC Showcase: Superman / Shazam!: The Return Of...\n",
        "16  $11.17    Ultimate Avengers Movie Collection (Widescreen)\n",
        "17   $5.00  The Next Avengers: Heroes Of Tomorrow (Widescr...\n",
        "18   $5.48          Ultimate Avengers: The Movie (Widescreen)\n",
        "19   $9.57     Ultimate Avengers 1 & 2 (Blu-ray) (Widescreen)"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### (2.5 * 4 = 10 points) Website 3: Facebook\n",
      "\n",
      "In the third task, we will scrape some specific sub-pages of Facebook profiles. In order to avoid using sophisticated tools like Selenium, for this task you can assume that the input to the function is the DOM of the relevant page. You can then use it to parse relevant contents."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# coding: utf-8\n",
      "\n",
      "# In[9]:\n",
      "\n",
      "#Input: dom - DOM of the books page corresponding to an FB account's profile. Eg, DOM of https://www.facebook.com/zuck/books\n",
      "#Output: An array (Python list) of books listed in the profile page. \n",
      "#    Note that this function requires a list as an output not a Pandas data frame\n",
      "# write a helper function that  reads this input file, converts it to DOM using Pattern and calls the function for parsing facebook.\n",
      " \n",
      "from collections import defaultdict\n",
      "import csv\n",
      "from bs4 import BeautifulSoup\n",
      "import urllib2\n",
      "import numpy as np\n",
      "\n",
      "html_text = open(\"/Users/dynajose/Desktop/DOM_HTML.rtf\").read()\n",
      "dom = BeautifulSoup(html_text) \n",
      "\n",
      "def scraping_facebook_books(dom):\n",
      "\n",
      "    f_data = bookDom.find_all(\"div\", {\"class\" : \"_gx6 _agv\"})\n",
      "    book=[]\n",
      "    for f_books in f_data:\n",
      "            books_title = f_books.find(\"a\",\"_gx7\")\n",
      "            books= books_title.text\n",
      "            book.append(books)\n",
      "    print book\n",
      "\n",
      "\n",
      "scraping_facebook_books(dom)\n",
      "\n",
      "\n",
      "\n",
      "# In[16]:\n",
      "\n",
      "#Input: dom - DOM of the groups page corresponding to an FB account's profile. Eg, DOM of https://www.facebook.com/zuck/groups\n",
      "#Output: A Pandas data frame with one row per group. \n",
      "#    It must have three columns - 'Group Name', 'Number of Members', 'Group Description'\n",
      "#    Note that all information of a group is in the same page (eg. https://www.facebook.com/zuck/groups)\n",
      "#    You can collect all data from same page even if they are incomplete (such as group description)\n",
      "#    Ensure that the column names as given above\n",
      "\n",
      "\n",
      "from collections import defaultdict\n",
      "import csv\n",
      "from bs4 import BeautifulSoup\n",
      "import urllib2\n",
      "import pandas as pd\n",
      "import re\n",
      "\n",
      "html_text = open(\"/Users/dynajose/Desktop/divyaGroup.rtf\").read()\n",
      "dom = BeautifulSoup(html_text) \n",
      "\n",
      "\n",
      "def scraping_facebook_groups(dom):\n",
      "    \n",
      "\n",
      "    data=defaultdict(list)   \n",
      "\n",
      "    group_data = bookDom.find_all(\"div\", {\"class\" :\"mtm\"})\n",
      "    #print group_data\n",
      "\n",
      "    for g_link in group_data:\n",
      "        try:\n",
      "            link=g_link.find_all(\"div\",{'class':'mbs fwb'})\n",
      "            for link_group in link:\n",
      "                link_text= link_group.find('a')\n",
      "                variable= link_text.text.strip()\n",
      "                data['Group Name'].append(variable)\n",
      "        except:\n",
      "            data['Group Name'].append(\"NA\")\n",
      "\n",
      "    for g_description in group_data:\n",
      "        try:\n",
      "            g_dec = g_description.find_all(\"div\",{'class':'mbs fcg'})\n",
      "            for g in g_dec:\n",
      "                d=g.text.strip()\n",
      "                data['Number of Members'].append(d)\n",
      "        except:\n",
      "                data['Number of Members'].append(\"NA\")\n",
      "\n",
      "\n",
      "    for g_members in group_data:\n",
      "        g_number = g_members.find_all(\"span\",{'class':\"_538r\"})\n",
      "        for number in g_number:\n",
      "            try:\n",
      "                n=number.text.strip()\n",
      "                data['Group Description'].append(n)\n",
      "            except:\n",
      "                data['Group Description'].append(\"NA\")\n",
      "\n",
      "\n",
      "    df = pd.DataFrame(data)\n",
      "    df\n",
      "    \n",
      "    return df\n",
      "\n",
      "\n",
      "scraping_facebook_groups(dom)\n",
      "\n",
      "\n",
      "# In[2]:\n",
      "\n",
      "#Input: dom - DOM of the music page corresponding to an FB account's profile. Eg, DOM of https://www.facebook.com/zuck/music\n",
      "#Output: A Pandas data frame with one row per group. \n",
      "#    It must have four columns \n",
      "#    'Name', 'Type' (eg. Musician/Band or Bands&Musicians) and 'Verified' (boolean: True/False), 'Profile Url'\n",
      "#    Note that all information of a group is in the same page (eg. https://www.facebook.com/zuck/music)\n",
      "#    Ensure that the column names as given above\n",
      "\n",
      "#def scraping_facebook_music(dom):\n",
      " #   return None\n",
      "\n",
      "from collections import defaultdict\n",
      "import csv\n",
      "from bs4 import BeautifulSoup\n",
      "import urllib2\n",
      "import pandas as pd\n",
      "import re\n",
      "\n",
      "text = open(\"/Users/dynajose/Desktop/PlayList.rtf\").read()\n",
      "dom = BeautifulSoup(text) \n",
      "\n",
      "def scraping_facebook_music(dom):\n",
      "    \n",
      "    data=defaultdict(list)\n",
      "    musicData=defaultdict(list)\n",
      "\n",
      "    f_music = dom.find_all(\"div\", {\"class\" : \"_gx6 _agv\"})\n",
      "\n",
      "    for music in f_music:\n",
      "        try:\n",
      "            Name_title = music.find(\"a\",\"_gx7\")\n",
      "            data['Name'].append(Name_title.text)\n",
      "        except:\n",
      "            data['Name'].append(\"NA\")\n",
      "\n",
      "        try:\n",
      "            type_title = music.find(\"div\",\"_1fs8 fsm fwn fcg\") \n",
      "            data['Type'].append(type_title.text)\n",
      "        except:\n",
      "            data['Type'].append(\"NA\") \n",
      "\n",
      "\n",
      "    for link_music in f_music:\n",
      "        try:\n",
      "            variable=link_music.find('a', href=re.compile('^https:'))['href']\n",
      "            data['Profile URL'].append(variable)\n",
      "        except:\n",
      "            data['Profile URL'].append(\"NA\")\n",
      "\n",
      "\n",
      "    for verified_page in f_music:\n",
      "        for page in verified_page:\n",
      "            page_verified = page.find_all('span',{'aria-label':'Verified Page'})\n",
      "            #print page_verified\n",
      "            check= \"Verified Page\"\n",
      "            for a in page_verified :\n",
      "                 if check in str(a) :\n",
      "                        data['Verified Page'].append(True)\n",
      "                 else :\n",
      "                        data['Verified Page'].append(False)\n",
      "\n",
      "\n",
      "    df = pd.DataFrame(data)\n",
      "    df\n",
      "    \n",
      "    return df\n",
      "\n",
      "scraping_facebook_music(dom)\n",
      "    \n",
      "\n",
      "\n",
      "# In[3]:\n",
      "\n",
      "#Let us now make things little bit more harder. \n",
      "#In all previous cases, you only had to collect information from a single page.\n",
      "# But in reality, you have to collect information and integrate from multiple pages.\n",
      "# Let us try a simple version of such data integration \n",
      "\n",
      "#Input: dom - DOM of the music page corresponding to an FB account's profile. Eg, DOM of https://www.facebook.com/zuck/movies\n",
      "#Output: A Pandas data frame with one row per group. \n",
      "#    It must have following columns - \n",
      "#        'Name', 'Type' (eg. Movie), 'Verified', 'Profile Url' - as before\n",
      "#        'Likes', 'Starring', 'Genre', 'Director', 'Movie URL'\n",
      "\n",
      "#    The first three columns can be obtained from https://www.facebook.com/zuck/movies\n",
      "#    Once you get the profile url, obtain the HTML of this url and use this content to obtain the last 5 column data\n",
      "#    For example, Zuckerberg likes 'The Matrix' (great movie btw). \n",
      "#    Then you get its profile url 'https://www.facebook.com/TheMatrixMovie?ref=profile'\n",
      "#    Get the text of this url using requests package and parse information from the About tab\n",
      "#    Ensure that the column names as given above\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "from collections import defaultdict\n",
      "import csv\n",
      "from bs4 import BeautifulSoup\n",
      "import urllib2\n",
      "import pandas as pd\n",
      "import re\n",
      "\n",
      "text = open(\"/Users/dynajose/Desktop/Movies.rtf\").read()\n",
      "dom = BeautifulSoup(text) \n",
      "\n",
      "\n",
      "def scraping_facebook_movies(dom):\n",
      "\n",
      "\n",
      "    data=defaultdict(list)\n",
      "    musicdata=defaultdict(list)\n",
      "\n",
      "    f_movies = dom.find_all(\"div\", {\"class\" : \"_gx6 _agv\"})\n",
      "\n",
      "    for movie in f_movies:\n",
      "        try:\n",
      "            Name_title = movie.find(\"a\",\"_gx7\")\n",
      "            data['Name'].append(Name_title.text)\n",
      "        except:\n",
      "            data['Name'].append(\"NA\")\n",
      "\n",
      "        try:\n",
      "            type_title = movie.find(\"div\",\"_1fs8 fsm fwn fcg\") \n",
      "            data['Type'].append(type_title.text)\n",
      "        except:\n",
      "            data['Type'].append(\"NA\") \n",
      "\n",
      "\n",
      "    for link_music in f_movies:\n",
      "        try:\n",
      "            variable=link_music.find('a', href=re.compile('^https:'))['href']\n",
      "            data['Profile URL'].append(variable)\n",
      "        except:\n",
      "            data['Profile URL'].append(\"NA\")\n",
      "\n",
      "    check= \"Verified Page\"\n",
      "    for a in f_movies :\n",
      "        if check in str(a) :\n",
      "            data['Verified'].append(True)\n",
      "        else :\n",
      "            data['Verified'].append(False)\n",
      "\n",
      "    df = pd.DataFrame(data)\n",
      "    df\n",
      "    \n",
      "    return df\n",
      "\n",
      "scraping_facebook_movies(dom)\n",
      "\n",
      "\n",
      "# In[59]:\n",
      "\n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "# In[59]:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# In[ ]:\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Part 2 and 3: Exploratory Analysis and Visualization\n",
      "======================\n",
      "\n",
      "Data Set Description\n",
      "---------------------\n",
      "\n",
      "In this assignment, you will use the FEC dataset. The US Federal Election Commission publishes data on contributions to political campaigns. This includes contributor names, occupation and employer, address, and contribution amount. Specifically, we will be using the FEC data from 2012 election between Barack Obama and Mitt Romney. This is widely considered as a landmark election as both sides spent an unprecedented amount of 1 Billion dollars each (i.e. more than 6000 Crores in INR each). If you are interested, you can download the entire list of contributor details at the [FEC site](http://www.fec.gov/disclosurep/PDownload.do). It is relatively large (150 MB compressed, 1 GB uncompressed). For our experiments, we will use a smaller subset of the data collected (and cleaned) by Wes McKinney (the creator of Pandas). For the download link, see the [Assignments page](http://saravanan-thirumuruganathan.github.io/cse5334Spring2015/assignments.html). It is small by most standards (around 1.4 million records, 20 MB compressed, 160 MB uncompressed) but large enough to give a taste of why data mining is compute intensive. Hopefully, this will also give you an appreciation as to the awesomeness of Pandas/Numpy - you can do really cool stuff with 2-3 lines of code that runs in seconds. \n",
      "\n",
      "**Dataset Description:** You can find the details (such as meaning of the column names) of the dataset in the [FEC website](ftp://ftp.fec.gov/FEC/Presidential_Map/2012/DATA_DICTIONARIES/CONTRIBUTOR_FORMAT.txt).\n",
      "\n",
      "While a knowledge of US Elections or FEC Campaign finance rules is not necessary for solving this assignment, you can check out the following links if you are curious. \n",
      "\n",
      "[How to Become the US President: A Step-by-Step Guide](http://2012election.procon.org/view.resource.php?resourceID=004333)\n",
      "\n",
      "[US Election guide: how does the election work?](http://www.telegraph.co.uk/news/worldnews/us-election/9480396/US-Election-guide-how-does-the-election-work.html)\n",
      "\n",
      "If you are fascinated with Campaign finance reform (as I am), here are some good links:\n",
      "\n",
      "[Super-PACs and Dark Money: ProPublica\u2019s Guide to the New World of Campaign Finance](http://www.propublica.org/blog/item/super-pacs-propublicas-guide-to-the-new-world-of-campaign-finance)\n",
      "\n",
      "[40 charts that explain money in politics](http://www.vox.com/2014/7/30/5949581/money-in-politics-charts-explain)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Visualization\n",
      "-------------\n",
      "\n",
      "Visualization is a key component of exploration. You will perform a number of 1-D and 2-D charts to get some intuition about the data. You can choose to use either Matplotlib or Seaborn for plotting. The default figures generated from Matplotlib might look a bit ugly. So you might want to try Seaborn to get better figures. The defaults in Seaborn are much saner and sometimes makes your life lot easier. Seaborn has number of styles - so feel free to experiment with them and choose the one you like. We have earmarked 10 points for the aesthetics of your visualizations.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pandas\n",
      "----------\n",
      "Almost all the tasks below could be purely solved using Pandas. Most analytic tasks should not require more than 2-3 lines of code (visualization on the other hand is a different matter - you might need 5-10 lines for each chart unless you use Seaborn). Here is a NON COMPREHENSIVE list of functions that you might want to know to solve this assignment : agg, apply, argmax, argmin, count, crosstab, cumsum, cut, describe, groupby, head, idxmax, idxmin, info, isin, map, max, min, pivot_table, size, sum, transform, unique, value_counts .\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Exploration Tasks\n",
      "==================\n",
      "\n",
      "You can find a set of exploratory analytics tasks below. Ensure that you clearly follow the instructions. The assignment will be graded automatically - so failure to follow might cause some issues. Also do NOT rename the functions or variables that the instructor has set. Of course, feel free to create new variables/functions that will hep your code. \n",
      "\n",
      "Reading and Filtering Dataset\n",
      "------------------------------\n",
      "The FEC data contains information about all presidential candidates. As a sitting president, Barack Obama was the only candidate from the Democratic party. In the Republican party, there was a process called Primary (see links above) where number of candidates competed to be the nominee. Mitt Romney won the Republican primary and competed with Barack Obama in the elections, which Obama won. \n",
      "\n",
      "The Python code below reads the FEC dataset into a Pandas data frame with the name fec_all. If your machine has less than 2 GB of RAM, then change the function argument low_memory to True. Once the frame is loaded, we remove all negative contributions (where the campaign refunded amount to a contributor for some reason). Finally, we create a new data frame called fec that contains the contributions to Barack Obama and Mitt Romney alone. \n",
      "\n",
      "For this code to work, the file 'fec_2012_contribution_subset.csv' must be in the same folder as the notebook. \n",
      "\n",
      "To reduce my typing, I might refer to Obama as BO and Romney as MR in the text below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#read the csv file into a Pandas data frame\n",
      "fec_all = pd.read_csv('fec_2012_contribution_subset.csv', low_memory=False)\n",
      "\n",
      "#We will be doing party wise analysis later. So, we want to associate each candidate with their party\n",
      "parties = {'Bachmann, Michelle': 'Republican',\n",
      "           'Cain, Herman': 'Republican',\n",
      "           'Gingrich, Newt': 'Republican',\n",
      "           'Huntsman, Jon': 'Republican',\n",
      "           'Johnson, Gary Earl': 'Republican',\n",
      "           'McCotter, Thaddeus G': 'Republican',\n",
      "           'Obama, Barack': 'Democrat',\n",
      "           'Paul, Ron': 'Republican',\n",
      "           'Pawlenty, Timothy': 'Republican',\n",
      "           'Perry, Rick': 'Republican',\n",
      "           \"Roemer, Charles E. 'Buddy' III\": 'Republican',\n",
      "           'Romney, Mitt': 'Republican',\n",
      "           'Santorum, Rick': 'Republican'}\n",
      "\n",
      "#create a new column called party that sets the value to the party of the candidate\n",
      "# The way this line works is as follows:\n",
      "#  1. fec_all.cand_nm gives a vector (or Series in Pandas terminology)\n",
      "#  2. For each row, the code looks up the candidate name to the dictionary parties\n",
      "#  3. If the name of the candidate (cand_nm) is in parties, it returns the value (i.e. Republican or Democrat)\n",
      "#  4. This whole thing is done for each row and you get another vector as output\n",
      "#  5. Finally, you create a new column in fec_all called 'party' and assign the vector you got to it.\n",
      "#  6. All in a single line :)\n",
      "fec_all['party'] = fec_all.cand_nm.map(parties)\n",
      "\n",
      "#ignore the refunds\n",
      "# Get the subset of dataset where contribution amount is positive\n",
      "fec_all = fec_all[fec_all.contb_receipt_amt > 0]\n",
      "\n",
      "#fec_all contains details about all presidential candidates. \n",
      "#fec contains the details about contributions to Barack Obama and Mitt Romney only\n",
      "#for the rest of the tasks, unless explicitly specified, work on the fec data frame.\n",
      "fec = fec_all[fec_all.cand_nm.isin(['Obama, Barack', 'Romney, Mitt'])]\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 134
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Task 1: Descriptive Statistics\n",
      "--------------------------------\n",
      "\n",
      "Let us start with some easy stuff. As of now, you do not know anything about the dataset. So the first task will be to get some basic sense. \n",
      "\n",
      " "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Task 1a: print the details of the data frame. \n",
      "# Basically, this should contain information such as number of rows,columns, name of columns, #non-null values for each column etc\n",
      "# Hint: there is a Pandas function to do this\n",
      "#replace None with your code\n",
      "print \"Task 1a: Details of FEC data frame are: \\n\", fec.info(verbose=True)\n",
      "\n",
      "#Task 1b: finding the number of rows and columns in the data frame.\n",
      "#Hint: find the property of the data frame that gives the number of rows and columns\n",
      "#replace None with your code\n",
      "t1b_num_rows = fec.shape[0]\n",
      "t1b_num_cols = fec.shape[1]\n",
      "print \"Task 1b: #Rows=%s, #Columns=%s\" % (t1b_num_rows, t1b_num_cols) \n",
      "\n",
      "#Task 1c: The only numeric data is 'contb_receipt_amt' which is the amount of contribution. \n",
      "# Print the descriptive details (min, max, quantiles etc) for 'contb_receipt_amt'\n",
      "#Hint: as above there is a direct pandas command for it.\n",
      "#replace None with your code\n",
      "print \"Task 1c: Descriptive details of contb_receipt_amt is \\n\", fec[\"contb_receipt_amt\"].describe()\n",
      "\n",
      "#Task 1d: Let us now print the number of unique values for few columns\n",
      "#Hint: Look for a Pandas function to do this.\n",
      "t1d_num_uniq_cand_id = fec[\"cand_id\"].unique()\n",
      "t1d_num_uniq_cand_nm = fec[\"cand_nm\"].unique()\n",
      "t1d_num_uniq_contbr_city = fec[\"contbr_city\"].unique()\n",
      "t1d_num_uniq_contbr_st = fec[\"contbr_st\"].unique()\n",
      "print \"Task 1d: #Uniq cand_id = \", len(t1d_num_uniq_cand_id)\n",
      "print \"Task 1d: #Uniq cand_nm = \", len(t1d_num_uniq_cand_nm)\n",
      "print \"Task 1d: #Uniq contbr_city = \", len(t1d_num_uniq_contbr_city)\n",
      "print \"Task 1d: #Uniq contbr_st = \", len(t1d_num_uniq_contbr_st)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Task 1a: Details of FEC data frame are: \n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Int64Index: 694282 entries, 411 to 701385\n",
        "Data columns (total 17 columns):\n",
        "cmte_id              694282 non-null object\n",
        "cand_id              694282 non-null object\n",
        "cand_nm              694282 non-null object\n",
        "contbr_nm            694282 non-null object\n",
        "contbr_city          694275 non-null object\n",
        "contbr_st            694278 non-null object\n",
        "contbr_zip           694234 non-null object\n",
        "contbr_employer      693607 non-null object\n",
        "contbr_occupation    693524 non-null object\n",
        "contb_receipt_amt    694282 non-null float64\n",
        "contb_receipt_dt     694282 non-null object\n",
        "receipt_desc         2345 non-null object\n",
        "memo_cd              87387 non-null object\n",
        "memo_text            90672 non-null object\n",
        "form_tp              694282 non-null object\n",
        "file_num             694282 non-null int64\n",
        "party                694282 non-null object\n",
        "dtypes: float64(1), int64(1), object(15)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "None\n",
        "Task 1b: #Rows=694282, #Columns=17\n",
        "Task 1c: Descriptive details of contb_receipt_amt is \n",
        "count     694282.000000\n",
        "mean         322.942745\n",
        "std         4482.130250\n",
        "min            0.010000\n",
        "25%           35.000000\n",
        "50%          100.000000\n",
        "75%          250.000000\n",
        "max      2014490.510000\n",
        "dtype: float64"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Task 1d: #Uniq cand_id = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "Task 1d: #Uniq cand_nm =  2\n",
        "Task 1d: #Uniq contbr_city =  11857\n",
        "Task 1d: #Uniq contbr_st =  68\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Task 2: Basic Filtering\n",
      "-----------------------\n",
      "In this task, we will perform some very high level filtering. Pandas has a convenient and powerful syntax for filtering (for eg, see above for how I filtered negative contributions and non-Obama, Romney candidates). "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Task 2a: Let us find out how much contributions did Obama and Romney made in this dataset\n",
      "# Remember, that this is not the complete amount as it excludes other sources like PACs, Super PACs and \n",
      "#  spending by party committes.\n",
      "#Hint: use cand_nm field\n",
      "t2a_tot_amt_obama = sum(fec.contb_receipt_amt[fec.cand_nm.isin(['Obama, Barack'])])\n",
      "t2a_tot_amt_romney = sum(fec.contb_receipt_amt[fec.cand_nm.isin(['Romney, Mitt'])])\n",
      "print \"Task 2a: Total Contribution for Obama is %s and for Romney is %s\" % (t2a_tot_amt_obama, t2a_tot_amt_romney)\n",
      "\n",
      "#Task 2b: How much contribution did folks from California, New York and Texas make totally (i.e. to both Obama and Romney).\n",
      "#use contbr_st field\n",
      "t2b_tot_amt_CA = sum(fec.contb_receipt_amt[fec.contbr_st.isin(['CA'])])\n",
      "t2b_tot_amt_NY = sum(fec.contb_receipt_amt[fec.contbr_st.isin(['NY'])])\n",
      "t2b_tot_amt_TX = sum(fec.contb_receipt_amt[fec.contbr_st.isin(['TX'])])\n",
      "print \"Task 2b: Total contributions from California is %s, New York is %s and Texas is %s\" % (t2b_tot_amt_CA, t2b_tot_amt_NY, t2b_tot_amt_TX)\n",
      "\n",
      "#Task 2c: Let us now use multiple filtering criteria\n",
      "# How much money did folks from Texas made to BO and MR?\n",
      "# How much money did folks from UT Arlington made to BO and MR?\n",
      "\n",
      "temp_t2c_tot_contr_tx_bo = fec[fec.cand_nm.isin(['Obama, Barack']) & fec.contbr_st.isin(['TX'])]\n",
      "t2c_tot_contr_tx_bo = temp_t2c_tot_contr_tx_bo['contb_receipt_amt'].sum()\n",
      "\n",
      "temp_t2c_tot_contr_tx_mr = fec[fec.cand_nm.isin(['Romney, Mitt']) & fec.contbr_st.isin(['TX'])]\n",
      "t2c_tot_contr_tx_mr = temp_t2c_tot_contr_tx_mr['contb_receipt_amt'].sum()\n",
      "\n",
      "temp_t2c_tot_contr_uta_bo = fec[fec.cand_nm.isin(['Obama, Barack']) & fec.contbr_employer.isin(['UT ARLINGTON'])]\n",
      "t2c_tot_contr_uta_bo = temp_t2c_tot_contr_uta_bo['contb_receipt_amt'].sum()\n",
      "\n",
      "temp_t2c_tot_contr_uta_mr = fec[fec.cand_nm.isin(['Romney, Mitt']) & fec.contbr_employer.isin(['UT ARLINGTON'])]\n",
      "t2c_tot_contr_uta_mr = temp_t2c_tot_contr_uta_mr['contb_receipt_amt'].sum()\n",
      "\n",
      "print \"Task 2c: From TX, BO got %s and MR got %s dollars\" % (t2c_tot_contr_tx_bo, t2c_tot_contr_tx_mr)\n",
      "print \"Task 2c: From UTA, BO got %s and MR got %s dollars\" % (t2c_tot_contr_uta_bo, t2c_tot_contr_uta_mr)\n",
      "\n",
      "#Task 2d: How much did Engineers from Google gave to BO and MR.\n",
      "# This task is a bit tricky as there are many variations: eg, SOFTWARE ENGINEER vs ENGINEER and GOOGLE INC. vs GOOGLE\n",
      "temp_t2d_tot_engr_goog_bo = fec[fec.cand_nm.isin(['Obama, Barack']) & fec.contbr_employer.str.contains('GOOGLE') & fec.contbr_occupation.str.contains('ENG')]\n",
      "t2d_tot_engr_goog_bo = temp_t2d_tot_engr_goog_bo['contb_receipt_amt'].sum()\n",
      "\n",
      "temp_t2d_tot_engr_goog_mr = fec[fec.cand_nm.isin(['Romney, Mitt']) & fec.contbr_employer.str.contains('GOOGLE') & fec.contbr_occupation.str.contains('ENG')]\n",
      "t2d_tot_engr_goog_mr = temp_t2d_tot_engr_goog_mr['contb_receipt_amt'].sum()\n",
      "\n",
      "print \"Task 2d: From Google Engineers, BO got %s and MR got %s dollars\" % (t2d_tot_engr_goog_bo, t2d_tot_engr_goog_mr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Task 2a: Total Contribution for Obama is 135877427.24 and for Romney is 88335907.53\n",
        "Task 2b: Total contributions from California is 35062620.84, New York is 24836131.14 and Texas is 12792822.13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Task 2c: From TX, BO got 6570832.45 and MR got 6221989.68 dollars"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Task 2c: From UTA, BO got 750.0 and MR got 0 dollars\n",
        "Task 2d: From Google Engineers, BO got 88312.4 and MR got 2850.0 dollars"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Task 3: Basic Aggregation \n",
      "--------------------------\n",
      "In this task, we will perform some very high level aggregation. Pandas has some convenient functions for aggregation (do NOT write a for loop - Pandas has some very efficient, vectorized code)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Task 3a: For each state, print the total contribution they made to both candidates. \n",
      "grouped_t3a_state_contr_both = fec.groupby(['contbr_st']).sum()\n",
      "t3a_state_contr_both = grouped_t3a_state_contr_both['contb_receipt_amt']\n",
      "print \"Task 3a: Total contribution made to both candidates by each state are:\\n\", t3a_state_contr_both\n",
      "\n",
      "#Task 3b: Now let us limit ourselves to TX. For each city in TX, print the total contribution made to both candidates\n",
      "temp_t3b_tx_city_contr_both = fec[fec.contbr_st.isin(['TX'])]\n",
      "grouped_t3b_tx_city_contr_both = temp_t3b_tx_city_contr_both.groupby(['contbr_city']).sum()\n",
      "t3b_tx_city_contr_both = grouped_t3b_tx_city_contr_both['contb_receipt_amt']\n",
      "print \"Task 3b: Total contribution made to both candidates by each city in TX are:\\n\", t3b_tx_city_contr_both\n",
      "\n",
      "#Task 3c: Now let us zoom into  Arlington, TX. For each zipcode in Arlington, print the total contribution made to both candidates\n",
      "temp_t3c_arlington_contr_both = fec[fec.contbr_st.isin(['TX']) & fec.contbr_city.isin(['ARLINGTON'])]\n",
      "grouped_t3c_arlington_contr_both = temp_t3c_arlington_contr_both.groupby(['contbr_zip']).sum()\n",
      "t3c_arlington_contr_both = grouped_t3c_arlington_contr_both['contb_receipt_amt']\n",
      "print \"Task 3c: Total contribution made to both candidates by each zipcode in Arlington are:\\n\", t3c_arlington_contr_both"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Task 3a: Total contribution made to both candidates by each state are:\n",
        "contbr_st\n",
        "AA              56540.00\n",
        "AB               2048.00\n",
        "AE              48653.75\n",
        "AK             368044.39\n",
        "AL            1070426.99\n",
        "AP              38785.50\n",
        "AR             464803.28\n",
        "AS               2955.00\n",
        "AZ            3394913.21\n",
        "CA           35062620.84\n",
        "CO            3639143.61\n",
        "CT            5567766.71\n",
        "DC            5398676.30\n",
        "DE             419381.14\n",
        "FF              99030.00\n",
        "...\n",
        "SC            1033475.80\n",
        "SD             253088.76\n",
        "TN            2636233.06\n",
        "TX           12792822.13\n",
        "UK               2500.00\n",
        "UT            4237151.85\n",
        "VA            7725743.04\n",
        "VI              84212.00\n",
        "VT            1041740.03\n",
        "WA            5592454.72\n",
        "WI            1400471.78\n",
        "WV             295879.59\n",
        "WY             446642.58\n",
        "XX             400250.00\n",
        "ZZ               5963.00\n",
        "Name: contb_receipt_amt, Length: 67, dtype: float64\n",
        "Task 3b: Total contribution made to both candidates by each city in TX are:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "contbr_city\n",
        "ABERNATHY          210.00\n",
        "ABILENE          45748.00\n",
        "ADDISON          12244.25\n",
        "ADKINS             600.00\n",
        "ALAMO              152.00\n",
        "ALAMO HEIGHTS     2500.00\n",
        "ALBA                69.00\n",
        "ALBANY            6500.00\n",
        "ALEDO             5880.00\n",
        "ALICE             2760.00\n",
        "ALLEN            21066.00\n",
        "ALLISON            474.00\n",
        "ALPINE            5166.00\n",
        "ALTO               120.00\n",
        "ALTON              125.00\n",
        "...\n",
        "WIMBERLEY      19060\n",
        "WINDCREST        525\n",
        "WINDTHORST       400\n",
        "WINFIELD        1000\n",
        "WINNIE           230\n",
        "WINNSBORO        375\n",
        "WOODLANDS       5112\n",
        "WOODVILLE        175\n",
        "WOODWAY         2965\n",
        "WORTHAM          250\n",
        "WYLIE           8405\n",
        "YANTIS           340\n",
        "YOAKUM           100\n",
        "YORKTOWN         100\n",
        "ZAPATA           300\n",
        "Name: contb_receipt_amt, Length: 729, dtype: float64\n",
        "Task 3c: Total contribution made to both candidates by each zipcode in Arlington are:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "contbr_zip\n",
        "75237            85\n",
        "76001          1130\n",
        "760015368      5175\n",
        "760015696       150\n",
        "760017554       300\n",
        "76002           904\n",
        "760023037       550\n",
        "760024202       215\n",
        "760025010      2474\n",
        "760025461        35\n",
        "760041185      1000\n",
        "76006         10050\n",
        "760062026       400\n",
        "760062725      1000\n",
        "760062778       365\n",
        "...\n",
        "760172730      125\n",
        "760172754     1000\n",
        "760172768       80\n",
        "760173004      135\n",
        "760173541      636\n",
        "760174554      200\n",
        "760176032      210\n",
        "760176250      145\n",
        "760177925       25\n",
        "760177973      650\n",
        "76018          105\n",
        "760181913      170\n",
        "760182501      100\n",
        "760184920      100\n",
        "760185108       35\n",
        "Name: contb_receipt_amt, Length: 121, dtype: float64\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Task 4: Aggregation+Filtering+Ranking\n",
      "-----------------------------------------\n",
      "In this task, you will try to combine aggregation with filtering and then rank the results based on the results. Pandas is often quite clever and might sort the data for you already. \n",
      "\n",
      "**Hint:** Pandas has ready made functions for all the following."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Task 4a: Print the number of contributors to Obama in each state.\n",
      "temp_t4a_num_contr_obama_per_state = fec[fec.cand_nm.isin(['Obama, Barack'])]\n",
      "t4a_num_contr_obama_per_state = temp_t4a_num_contr_obama_per_state.groupby(['contbr_st']).contbr_nm.nunique()\n",
      "print \"Number of contributions to Obama in each state is:\\n\", t4a_num_contr_obama_per_state\n",
      "\n",
      "#Task 4b: Print the top-10 states (based on number of contributors) that contributed to Obama.\n",
      "# print both state name and number of contributors\n",
      "temp_t4b_top10_obama_contr_states = fec[fec.cand_nm.isin(['Obama, Barack'])]\n",
      "grouped_t4b_top10_obama_contr_states = temp_t4b_top10_obama_contr_states.groupby('contbr_st').contbr_nm.nunique().order(ascending=False)\n",
      "t4b_top10_obama_contr_states = grouped_t4b_top10_obama_contr_states[0:10]\n",
      "print \"\\nTop-10 states with most contributors to Obama are:\\n\", t4b_top10_obama_contr_states\n",
      "\n",
      "#Task 4c: Print the top-20 occupations that contributed overall (to both BO and MR)\n",
      "grouped_t4c_top20_contr_occupation = fec.groupby('contbr_occupation').contb_receipt_amt.sum().order(ascending=False)\n",
      "t4c_top20_contr_occupation = grouped_t4c_top20_contr_occupation[0:20]\n",
      "print \"\\nTop-20 Occupations with most contributors are:\\n\", t4c_top20_contr_occupation\n",
      "\n",
      "#Task 4d: Print the top-10 Employers that contributed overall (to both BO and MR)\n",
      "grouped_t4d_top10_contr_employer_all = fec.groupby('contbr_employer').contb_receipt_amt.sum().order(ascending=False)\n",
      "t4d_top10_contr_employer_all = grouped_t4d_top10_contr_employer_all[0:10]\n",
      "print \"\\nTop-10 Employers with most contributors are:\\n\", t4d_top10_contr_employer_all"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of contributions to Obama in each state is:\n",
        "contbr_st\n",
        "AA              40\n",
        "AB               1\n",
        "AE             122\n",
        "AK             597\n",
        "AL            1194\n",
        "AP              53\n",
        "AR             630\n",
        "AS               5\n",
        "AZ            3200\n",
        "CA           32475\n",
        "CO            3982\n",
        "CT            3169\n",
        "DC            4342\n",
        "DE             608\n",
        "FL            9857\n",
        "...\n",
        "QU              1\n",
        "RI            713\n",
        "SC           1328\n",
        "SD            219\n",
        "TN           2212\n",
        "TX           9932\n",
        "UT            841\n",
        "VA           7084\n",
        "VI            117\n",
        "VT           1498\n",
        "WA           6866\n",
        "WI           2523\n",
        "WV            418\n",
        "WY            318\n",
        "ZZ              6\n",
        "Name: contbr_nm, Length: 64, dtype: int64\n",
        "\n",
        "Top-10 states with most contributors to Obama are:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "contbr_st\n",
        "CA           32475\n",
        "NY           17548\n",
        "IL           10726\n",
        "TX            9932\n",
        "FL            9857\n",
        "MA            8743\n",
        "MD            7551\n",
        "VA            7084\n",
        "WA            6866\n",
        "PA            6445\n",
        "Name: contbr_nm, dtype: int64\n",
        "\n",
        "Top-20 Occupations with most contributors are:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "contbr_occupation\n",
        "RETIRED                                   36813589.97\n",
        "ATTORNEY                                  16506701.79\n",
        "HOMEMAKER                                 12396322.02\n",
        "INFORMATION REQUESTED PER BEST EFFORTS    11396894.84\n",
        "PHYSICIAN                                  5103148.90\n",
        "INFORMATION REQUESTED                      4866973.96\n",
        "PRESIDENT                                  4369754.84\n",
        "CONSULTANT                                 3884806.72\n",
        "EXECUTIVE                                  3656108.08\n",
        "LAWYER                                     3168184.07\n",
        "CEO                                        2429195.71\n",
        "INVESTOR                                   2421728.12\n",
        "PROFESSOR                                  2326433.20\n",
        "C.E.O.                                     1970076.11\n",
        "OWNER                                      1876753.60\n",
        "SELF-EMPLOYED                              1764931.84\n",
        "NOT EMPLOYED                               1709188.20\n",
        "REAL ESTATE                                1583703.09\n",
        "FINANCE                                    1439623.65\n",
        "TEACHER                                    1392307.54\n",
        "Name: contb_receipt_amt, dtype: float64\n",
        "\n",
        "Top-10 Employers with most contributors are:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "contbr_employer\n",
        "RETIRED                                   34200584.56\n",
        "SELF-EMPLOYED                             24490846.94\n",
        "INFORMATION REQUESTED PER BEST EFFORTS    12059527.24\n",
        "HOMEMAKER                                 10752604.76\n",
        "NOT EMPLOYED                               8588808.70\n",
        "INFORMATION REQUESTED                      5053480.37\n",
        "SELF                                       1079931.20\n",
        "STUDENT                                     815322.39\n",
        "SELF EMPLOYED                               470144.24\n",
        "MORGAN STANLEY                              322614.10\n",
        "Name: contb_receipt_amt, dtype: float64\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Task 5: Basic Visualization\n",
      "-----------------------------\n",
      "\n",
      "Let us take a break from analytics to do some Visualization. Notice that the visualization tasks are NOT ordered based on their complexity. So some of them might be more challenging than others."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Task 5a: Draw a \"horizontal\" bar chart with one bar each for Obama and Romney with the \n",
      "#value corresponding to total amount they raised.\n",
      "# Remember to make the bar chart into a horizontal bar chart\n",
      "#########################begin code for Task 5a\n",
      "df5a = DataFrame(fec.groupby(['cand_nm']).contb_receipt_amt.sum())\n",
      "fig = plt.figure()\n",
      "df5a.plot(kind='barh',title='Task 5a: Total amount raised each for Obama and Romney')\n",
      "plt.xlabel('Total amount raised')\n",
      "plt.ylabel('Candidate Name')\n",
      "#########################end code for Task 5a\n",
      "\n",
      "#Task 5b: Draw the \"horizontal\" bar chart of total NUMBER of contributions made per Candidate.\n",
      "# ie Candidate name vs number of contributions for that candidate\n",
      "#########################begin code for Task 5b\n",
      "df5b = DataFrame( fec.groupby(['cand_nm']).contb_receipt_amt.count())\n",
      "fig = plt.figure()\n",
      "df5b.plot(kind='barh',title='Task 5b: Number of contributions per Candidate')\n",
      "plt.xlabel('Total number of contributions')\n",
      "plt.ylabel('Candidate Name')\n",
      "#########################end code for Task 5b\n",
      "\n",
      "#Task 5c: Draw the \"horizontal\" bar chart of average contributions made per Candidate.\n",
      "# ie Candidate Name vs avg contribution\n",
      "#########################begin code for Task 5c\n",
      "df5c = DataFrame(fec.groupby(['cand_nm']).contb_receipt_amt.mean())\n",
      "fig = plt.figure()\n",
      "df5c.plot(kind='barh',title='Task 5c: Average contributions per Candidate')\n",
      "plt.xlabel('Average contributions')\n",
      "plt.ylabel('Candidate Name')\n",
      "#########################end code for Task 5c\n",
      "\n",
      "\n",
      "#Task 5d: Draw a \"horizontal\" bar chart that lists the top-10 states based on the \n",
      "#TOTAL contribution they made to both candidates\n",
      "# For each state, draw two lines - one in blue for Obama and one in red for Romney\n",
      "# Display the proportion of the total contribution that came from the state.\n",
      "# For eg, if Obama made 1 billion and TX gave 100 million of it, the proportion is 10% \n",
      "# Remember to make the bar chart into a horizontal bar chart\n",
      "#---------------------------------------------------------------------------------\n",
      "#professors' clarification\n",
      "#Let me give an example with 3 states. Please generalize to top-10 states.\n",
      " \n",
      "#Suppose CA, TX and NY be the top-3 states based on total contribution.\n",
      "#Suppose Obama and Romney made 1 Billion in total each.\n",
      "#Suppose Obama 200M, 150M,100M from CA,TX,NY. This corresponds to 20%, 15% and 10% of total of Obama.\n",
      "#Suppose Romney made 100M, 200M, 100M from CA,TX,NY. This is 10%,20%,10% of total.\n",
      "#So you horizontal bar chart will have the following information:\n",
      "\n",
      "#CA: Obama: 20, Romney 10\n",
      "#TX: Obama: 15, Romney 20\n",
      "#NY: Obama: 10, Romney 10\n",
      "#########################begin code for Task 5d\n",
      "df5d = DataFrame(fec.groupby(['contbr_st']).contb_receipt_amt.sum().order(ascending=False)[0:10])\n",
      "df5d['obama_total'] = sum(fec.contb_receipt_amt[fec.cand_nm.isin(['Obama, Barack'])])\n",
      "df5d['romney_total'] = sum(fec.contb_receipt_amt[fec.cand_nm.isin(['Romney, Mitt'])])\n",
      "ix5d = Series(df5d.index)\n",
      "df5d['obama_st_donation'] = fec[fec.contbr_st.isin(ix5d) & fec.cand_nm.isin(['Obama, Barack'])].groupby(['contbr_st']).contb_receipt_amt.sum()\n",
      "df5d['romney_st_donation'] = fec[fec.contbr_st.isin(ix5d) & fec.cand_nm.isin(['Romney, Mitt'])].groupby(['contbr_st']).contb_receipt_amt.sum()\n",
      "df5d['obama_percentage'] = df5d.obama_st_donation/df5d.obama_total * 100\n",
      "df5d['romney_percentage'] = df5d.romney_st_donation/df5d.romney_total * 100\n",
      "df5d = pd.DataFrame({'Obama': df5d.obama_percentage,'Romney': df5d.romney_percentage}, index=ix5d)\n",
      "\n",
      "fig = plt.figure()\n",
      "df5d.plot(kind='barh',secondary_y=True,title='Task5d: Proportion of the total contribution from each state')\n",
      "plt.legend(loc=1)\n",
      "\n",
      "plt.tick_params(axis='y',which='both',labelleft='on', labelright='off')\n",
      "\n",
      "ax = plt.gca()\n",
      "plt.ylabel('States')\n",
      "ax.yaxis.set_label_position('left')\n",
      "\n",
      "# Not working\n",
      "plt.xlabel('Proportion of the total contribution')\n",
      "ax.xaxis.set_label_text('Proportion of the total contribution')\n",
      "ax.xaxis.set_label_position('bottom')\n",
      "#########################end code for Task 5d\n",
      "\n",
      "\n",
      "#Task 5e: Now repeat the same process based on Occupation (again top-10)\n",
      "#########################begin code for Task 5e\n",
      "df5e = DataFrame(fec.groupby(['contbr_occupation']).contb_receipt_amt.sum().order(ascending=False)[0:10])\n",
      "df5e['obama_total'] = sum(fec.contb_receipt_amt[fec.cand_nm.isin(['Obama, Barack'])])\n",
      "df5e['romney_total'] = sum(fec.contb_receipt_amt[fec.cand_nm.isin(['Romney, Mitt'])])\n",
      "ix5e = Series(df5e.index)\n",
      "#print ix5e\n",
      "df5e['obama_occupation_donation'] = fec[fec.contbr_occupation.isin(ix5e) & fec.cand_nm.isin(['Obama, Barack'])].groupby(['contbr_occupation']).contb_receipt_amt.sum()\n",
      "df5e['romney_occupation_donation'] = fec[fec.contbr_occupation.isin(ix5e) & fec.cand_nm.isin(['Romney, Mitt'])].groupby(['contbr_occupation']).contb_receipt_amt.sum()\n",
      "df5e['obama_percentage'] = df5e.obama_occupation_donation/df5e.obama_total * 100\n",
      "df5e['romney_percentage'] = df5e.romney_occupation_donation/df5e.romney_total * 100\n",
      "df5e = pd.DataFrame({'Obama': df5e.obama_percentage,'Romney': df5e.romney_percentage}, index=ix5e)\n",
      "\n",
      "fig = plt.figure()\n",
      "df5e.plot(kind='barh',secondary_y=True,title='Task5e: Proportion of the total contribution based on Occupation')\n",
      "plt.legend(loc=1)\n",
      "\n",
      "plt.tick_params(axis='y',which='both',labelleft='on', labelright='off')\n",
      "\n",
      "ax = plt.gca()\n",
      "ax.yaxis.set_label_position('left')\n",
      "plt.ylabel('Occupation')\n",
      "#########################end code for Task 5e\n",
      "\n",
      "\n",
      "#Task 5f: Now repeat the same process based on Employers (again top-10)\n",
      "#########################begin code for Task 5f\n",
      "df5f = DataFrame(fec.groupby(['contbr_employer']).contb_receipt_amt.sum().order(ascending=False)[0:10])\n",
      "df5f['obama_total'] = sum(fec.contb_receipt_amt[fec.cand_nm.isin(['Obama, Barack'])])\n",
      "df5f['romney_total'] = sum(fec.contb_receipt_amt[fec.cand_nm.isin(['Romney, Mitt'])])\n",
      "ix5f = Series(df5f.index)\n",
      "#print ix5f\n",
      "df5f['obama_employer_donation'] = fec[fec.contbr_employer.isin(ix5f) & fec.cand_nm.isin(['Obama, Barack'])].groupby(['contbr_employer']).contb_receipt_amt.sum()\n",
      "df5f['romney_employer_donation'] = fec[fec.contbr_employer.isin(ix5f) & fec.cand_nm.isin(['Romney, Mitt'])].groupby(['contbr_employer']).contb_receipt_amt.sum()\n",
      "df5f['obama_percentage'] = df5f.obama_employer_donation/df5f.obama_total * 100\n",
      "df5f['romney_percentage'] = df5f.romney_employer_donation/df5f.romney_total * 100\n",
      "\n",
      "fig = plt.figure()\n",
      "df5f = pd.DataFrame({'Obama': df5f.obama_percentage,'Romney': df5f.romney_percentage}, index=ix5f)\n",
      "#print df5f\n",
      "df5f.plot(kind='barh',secondary_y=True,title='Task5e: Proportion of the total contribution based on Employers')\n",
      "plt.legend(loc=1)\n",
      "\n",
      "plt.tick_params(axis='y',which='both',labelleft='on', labelright='off')\n",
      "\n",
      "ax = plt.gca()\n",
      "ax.yaxis.set_label_position('left')\n",
      "plt.ylabel('Employers')\n",
      "#########################end code for Task 5f\n",
      "\n",
      "\n",
      "#Task 5g: Draw the histogram of total NUMBER of contributions made per each state.\n",
      "# X-axis : state, Y-axis : number of contribution from that state\n",
      "#########################begin code for Task 5g\n",
      "\n",
      "# Get count of number of contributions grouped by each state\n",
      "df5g = DataFrame(fec.groupby(['contbr_st']).contb_receipt_amt.count().order(ascending=False))\n",
      "# Change result dataframe column name from contb_receipt_amt to a meaningful name\n",
      "df5g.columns = ['Count of Contributions']\n",
      "# print df5g\n",
      "\n",
      "# Below line is actually not required\n",
      "# df5g = pd.DataFrame({'data1': df5g.contb_receipt_amt}, index=df5g.index)\n",
      "# print df5g\n",
      "\n",
      "fig = plt.figure()\n",
      "# Plot bar chart as Histogram is not possible for this X and Y-Axes variables\n",
      "df5g.plot(kind='bar',title='Task 5g: Histogram of total NUMBER of contributions made per each state',figsize=(20,5))\n",
      "# Label the axes\n",
      "# plt.suptitle('Task 5g: Histogram of total NUMBER of contributions made per each state', fontsize=14, fontweight='bold')\n",
      "plt.xlabel('States')\n",
      "plt.ylabel('Number of Contributions per State')\n",
      "# plt.close()\n",
      "\n",
      "# In below line, kind='hist' is not working\n",
      "#df5g.plot(kind='hist')\n",
      "#########################end code for Task 5g\n",
      "\n",
      "#Task 5h: Draw a histogram of actual contributions made for Obama. Set bin size as 50\n",
      "#X-axis: contribution amount bin, Y-axis: frequency\n",
      "#########################begin code for Task 5h\n",
      "df5h = DataFrame((fec.contb_receipt_amt[fec.cand_nm.isin(['Obama, Barack'])]))\n",
      "\n",
      "# Below line is not mandatory\n",
      "# df5h['contb_receipt_amt'] = df5h['contb_receipt_amt'].apply(np.nan_to_num)\n",
      "\n",
      "df5h_list = df5h['contb_receipt_amt'].tolist()\n",
      "# print df5h_list\n",
      "list_min = int(min(df5h_list))\n",
      "# print list_min\n",
      "list_max = int(max(df5h_list)) + 1\n",
      "# print list_max\n",
      "\n",
      "bins = []\n",
      "binsize = 50\n",
      "for i in range(list_min+binsize,list_max,binsize):\n",
      "    bins.append(i)\n",
      "# bins = [1,5,10,50,100,150,200,250,300,350,400,450,500,1000,2000,3000,4000,5000,10000,2014500]\n",
      "# print bins\n",
      "\n",
      "fig = plt.figure()\n",
      "plt.hist(df5h_list,bins)\n",
      "plt.gca().set_xscale(\"log\")\n",
      "plt.title('Task5h: Histogram of actual contributions made for Obama (Drawn to Log Scale)',y=1.08)\n",
      "plt.xlabel('Contribution Amount Bin')\n",
      "plt.ylabel('Frequency')\n",
      "#########################end code for Task 5h\n",
      "\n",
      "#Task 5i: Draw a histogram of actual contributions made for Romney. Set bin size as 50\n",
      "#X-axis: contribution amount bin, Y-axis: frequency\n",
      "#########################begin code for Task 5i\n",
      "df5i=DataFrame((fec.contb_receipt_amt[fec.cand_nm.isin(['Romney, Mitt'])]))\n",
      "\n",
      "df5i_list = df5i['contb_receipt_amt'].tolist()\n",
      "# print df5i_list\n",
      "list_min = int(min(df5i_list))\n",
      "# print list_min\n",
      "list_max = int(max(df5i_list)) + 1\n",
      "# print list_max\n",
      "\n",
      "bins = []\n",
      "binsize = 50\n",
      "for i in range(list_min+binsize,list_max,binsize):\n",
      "    bins.append(i)\n",
      "# print bins\n",
      "\n",
      "fig = plt.figure()\n",
      "plt.hist(df5i_list,bins)\n",
      "plt.gca().set_xscale(\"log\")\n",
      "plt.title('Task5i: Histogram of actual contributions made for Romney (Drawn to Log Scale)',y=1.08)\n",
      "plt.xlabel('Contribution Amount Bin')\n",
      "plt.ylabel('Frequency')\n",
      "#########################end code for Task 5i\n",
      "\n",
      "#Harder\n",
      "#Task 5j: Draw a line chart showing how the campaign contribution of Obama and Romney varied every quarter\n",
      "#Use blue for Obama and red for Romney\n",
      "#This is a bit tricky because, you have to convert contribution date to quarter.\n",
      "#You can either do it on your own or see if Pandas has some function\n",
      "#########################begin code for Task 5j\n",
      "df5j_Obama = DataFrame(fec.contb_receipt_dt[fec.cand_nm.isin(['Obama, Barack'])]).apply(pd.to_datetime)\n",
      "# print df5j_Obama['contb_receipt_dt'].dtype\n",
      "\n",
      "df5j_list_Obama = df5j_Obama['contb_receipt_dt'].tolist()\n",
      "# print df5j_list_Obama\n",
      "i=0\n",
      "for i in range(len(df5j_list_Obama)):\n",
      "    df5j_list_Obama[i] = str(df5j_list_Obama[i].year) + \"-\" + str(df5j_list_Obama[i].quarter)\n",
      "# print df5j_list_Obama\n",
      "\n",
      "df5j_Obama = DataFrame(fec[fec.cand_nm.isin(['Obama, Barack'])].contb_receipt_amt)\n",
      "df5j_Obama ['year_quarter'] = df5j_list_Obama\n",
      "\n",
      "df5j_Obama_year_quarter_amount_sum = df5j_Obama.groupby(['year_quarter']).contb_receipt_amt.sum()\n",
      "# print df5j_Obama_year_quarter_amount_sum\n",
      "\n",
      "\n",
      "\n",
      "df5j_Romney = DataFrame(fec.contb_receipt_dt[fec.cand_nm.isin(['Romney, Mitt'])]).apply(pd.to_datetime)\n",
      "# print df5j_Romney['contb_receipt_dt'].dtype\n",
      "\n",
      "df5j_list_Romney = df5j_Romney['contb_receipt_dt'].tolist()\n",
      "# print df5j_list_Romney\n",
      "i=0\n",
      "for i in range(len(df5j_list_Romney)):\n",
      "    df5j_list_Romney[i] = str(df5j_list_Romney[i].year) + \"-\" + str(df5j_list_Romney[i].quarter)\n",
      "# print df5j_list_Romney\n",
      "\n",
      "df5j_Romney = DataFrame(fec[fec.cand_nm.isin(['Romney, Mitt'])].contb_receipt_amt)\n",
      "df5j_Romney ['year_quarter'] = df5j_list_Romney\n",
      "\n",
      "df5j_Romney_year_quarter_amount_sum = df5j_Romney.groupby(['year_quarter']).contb_receipt_amt.sum()\n",
      "# print df5j_Romney_year_quarter_amount_sum\n",
      "\n",
      "\n",
      "\n",
      "df5j = pd.DataFrame({'Obama': df5j_Obama_year_quarter_amount_sum,'Romney': df5j_Romney_year_quarter_amount_sum})\n",
      "fig = plt.figure()\n",
      "df5j.plot(color='br')\n",
      "# plt.plot(df5j['Obama'],'b',df5j['Romney'],'r')\n",
      "plt.title('Task5j: Variation of Campaign Contribution of Obama and Romeny every quarter',y=1.08)\n",
      "plt.xlabel('Year-Quarter')\n",
      "plt.ylabel('Contribution')\n",
      "#########################end code for Task 5j\n",
      "\n",
      "#Harder\n",
      "#Task 5k: Draw a line chart showing the CUMULATIVE campaign contribution of Obama and Romney varied every quarter\n",
      "# In other words, if Obama made X, Y, Z in first, second and third quarters\n",
      "#  then plot X for first quarter, X+Y for second quarter and X+Y+Z for third quarter.\n",
      "#Use blue for Obama and red for Romney\n",
      "#This is a bit tricky because, you have to convert contribution date to quarter.\n",
      "#You can either do it on your own or see if Pandas has some function\n",
      "#########################begin code for Task 5k\n",
      "df5k_Obama_year_quarter_amount_cumsum = df5j_Obama.groupby(['year_quarter']).contb_receipt_amt.sum().cumsum()\n",
      "# print df5k_Obama_year_quarter_amount_cumsum\n",
      "\n",
      "df5k_Romney_year_quarter_amount_cumsum = df5j_Romney.groupby(['year_quarter']).contb_receipt_amt.sum().cumsum()\n",
      "# print df5k_Romney_year_quarter_amount_cumsum\n",
      "\n",
      "df5k = pd.DataFrame({'Obama': df5k_Obama_year_quarter_amount_cumsum,'Romney': df5k_Romney_year_quarter_amount_cumsum})\n",
      "fig = plt.figure()\n",
      "df5k.plot(color='br')\n",
      "plt.title('Task5k: Variation of Cumulative Campaign Contribution of Obama and Romeny every quarter',y=1.08)\n",
      "plt.xlabel('Year-Quarter')\n",
      "plt.ylabel('Cumulative Contribution')\n",
      "#########################end code for Task 5k\n",
      "\n",
      "#Tasks 5l and 5m\n",
      "#Repeat 5j and 5k but do it for NUMBER of contributors\n",
      "#In other words, 5l plots the number of contributors for Obama and Romney, quarter over quarter\n",
      "#5m plots cumulative number of contributors quarter over quarter.\n",
      "#########################begin code for Task 5l\n",
      "df5l_Obama_year_quarter_amount_count = df5j_Obama.groupby(['year_quarter']).contb_receipt_amt.count()\n",
      "# print df5j_Obama_year_quarter_amount_count\n",
      "\n",
      "df5l_Romney_year_quarter_amount_count = df5j_Romney.groupby(['year_quarter']).contb_receipt_amt.count()\n",
      "# print df5j_Obama_year_quarter_amount_count\n",
      "\n",
      "df5l = pd.DataFrame({'Obama': df5l_Obama_year_quarter_amount_count,'Romney': df5l_Romney_year_quarter_amount_count})\n",
      "fig = plt.figure()\n",
      "df5l.plot(color='br')\n",
      "plt.title('Task5l: Variation of Number of Contributors of Obama and Romeny every quarter',y=1.08)\n",
      "plt.xlabel('Year-Quarter')\n",
      "plt.ylabel('Number of Contributors')\n",
      "#########################end code for Task 5l\n",
      "\n",
      "\n",
      "#########################begin code for Task 5m\n",
      "df5m_Obama_year_quarter_amount_count_cumsum = df5j_Obama.groupby(['year_quarter']).contb_receipt_amt.count().cumsum()\n",
      "df5m_Romney_year_quarter_amount_count_cumsum = df5j_Romney.groupby(['year_quarter']).contb_receipt_amt.count().cumsum()\n",
      "\n",
      "df5m = pd.DataFrame({'Obama': df5m_Obama_year_quarter_amount_count_cumsum,'Romney': df5m_Romney_year_quarter_amount_count_cumsum})\n",
      "fig = plt.figure()\n",
      "df5m.plot(color='br')\n",
      "plt.title('Task5m: Variation of Cumulative Number of Contributors of Obama and Romeny every quarter',y=1.08)\n",
      "plt.xlabel('Year-Quarter')\n",
      "plt.ylabel('Cumulative Number of Contributors')\n",
      "#########################end code for Task 5m"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "datetime64[ns]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "'\\n#Harder\\n#Task 5k: Draw a line chart showing the CUMULATIVE campaign contribution of Obama and Romney varied every quarter\\n# In other words, if Obama made X, Y, Z in first, second and third quarters\\n#  then plot X for first quarter, X+Y for second quarter and X+Y+Z for third quarter.\\n#Use blue for Obama and red for Romney\\n#This is a bit tricky because, you have to convert contribution date to quarter.\\n#You can either do it on your own or see if Pandas has some function\\n#########################begin code for Task 5k\\n#########################end code for Task 5k\\n\\n\\n#Tasks 5l and 5m\\n#Repeat 5j and 5k but do it for NUMBER of contributors\\n#In other words, 5l plots the number of contributors for Obama and Romney, quarter over quarter\\n#5m plots cumulative number of contributors quarter over quarter.\\n\\n#########################begin code for Task 5l\\n#########################end code for Task 5l\\n\\n\\n#########################begin code for Task 5m\\n#########################end code for Task 5m\\n'"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Task 6: Discretization\n",
      "-----------------------\n",
      "\n",
      "Recall the IMDB dataset that we discussed in the class where we were able to draw lot more interesting plots. The key challenge here is that most of the attributes have too many values (ie. the domain cardinality is very large). There are few ways to work around this issue. We already did something above (ie focussing only top-k). The other option is **discretization** where we create buckets and put contributions based on the buckets. Discretization in Pandas is acheived  by cut function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "#The following set of tasks are a bit tricky: \n",
      "#    you need to use multiple commands to achieve. Specifically look at cut, groupby and unstack\n",
      "\n",
      "#Task 6a: Discretize the contributions of Obama and Romney based on the bins given below.\n",
      "# For example, if Obama got contributions such as 2, 6, 16, 18, 120, then he has \n",
      "#  0 contribution in (0,1], 2 contributions in (1,10], 2 contributions in (10, 100] and 1 contribution in (100, 1000]\n",
      "bins = np.array([0, 1, 10, 100, 1000, 10000, 100000, 1000000, 10000000])\n",
      "labels = pd.cut(fec.contb_receipt_amt,bins)# set the variable labels to the output of pd.cut\n",
      "df6a = DataFrame(fec)\n",
      "df6a['bins']= labels\n",
      "grouped = df6a.groupby(['bins','cand_nm'])\n",
      "#Replace None below in the print statement with grouped.size().unstack(0) . \n",
      "#    If your code for labels and grouped is correct, this should print number of people in each bin per candidate\n",
      "print grouped.size().unstack(0)\n",
      "\n",
      "\n",
      "#Task 6b: In Task 6a, we calculated the COUNT (i.e. the number of contributors in each bin)\n",
      "# This by itself is not sufficient.\n",
      "# In this task, let us compute the TOTAL AMOUNT in each bucket.\n",
      "# Specifically, compute for each candidate the total amount of contributions that each got in each bucket.\n",
      "# Continuing the example above, Obama's total contribution in each bucket is\n",
      "#  0 in (0,1], 8 in (1,10], 34 in (10, 100] and 120 in (100, 1000]\n",
      "#This could be done in 1 line from the variable grouped above\n",
      "t6b_bucket_sums = grouped.contb_receipt_amt.sum()\n",
      "print t6b_bucket_sums\n",
      "\n",
      "\n",
      "#Task 6c: Even this does not fully specify the disparity in the funding scenario.\n",
      "# To see this let us now compute the PROPORTION of total contribution in each bucket\n",
      "# This is called normalization and is a common operation. \n",
      "# Typically normalization is done over the same candidate.\n",
      "# But for the point I am trying to make, let us normalize within bucket.\n",
      "# For example, if obama made X in a bucket and Y in another bucket, \n",
      "#    then normalization will give X/(X+Y) for Obama and Y/(X+Y) for Romney\n",
      "# This is also quite easy in Pandas and can be done in 1 line\n",
      "# The key idea is to realize that sum function takes an argument called axis\n",
      "#  that does different things for axis=0 and axis=1 (figure out which does what)\n",
      "\n",
      "bins = np.array([0, 1, 10, 100, 1000, 10000, 100000, 1000000, 10000000])\n",
      "labels = pd.cut(fec.contb_receipt_amt,bins)# set the variable labels to the output of pd.cut\n",
      "#print labels.describe()\n",
      "df6c = DataFrame(fec)\n",
      "df6c['bins']= labels\n",
      "\n",
      "newdf =  df6c.groupby(['cand_nm','bins']).contb_receipt_amt.sum()\n",
      "print newdf.div(np.nansum(t6b_bucket_sums,axis=1))\n",
      "\n",
      "\n",
      "\n",
      "df6c_new= pd.DataFrame(df6c.bins)\n",
      "df6c_new ['contb_receipt_amt'] = df6c.contb_receipt_amt\n",
      "#df6c_new ['contb_receipt_amt'] = df6c_new.contb_receipt_amt.apply(np.nan_to_num)\n",
      "df6c_new ['cand_nm'] = df6c.cand_nm\n",
      "#df6c_new ['bin_sum'] = df6c_new.groupby['binlabel']\n",
      "print df6c_new\n",
      "#print t6c_normed_bucket_sums\n",
      "\n",
      "'''\n",
      "#Once you have done this , uncomment the following line to a horizontal stacked bar chart\n",
      "#t6c_normed_bucket_sums[:-2].plot(kind='barh', stacked=True)\n",
      "\n",
      "\n",
      "#Task 6d: Let us go back and try to do the other analysis\n",
      "# Let us now try to see what PROPORTION of each candidate's amount came from each bucket.\n",
      "#  This is the classical case of normalization.\n",
      "#  Continuing the example above, Obama has made 0+8+34+120=162\n",
      "#  We can normalize it by diving each bucket by the total\n",
      "#   For example, 0/162, 8/162, 34/162 and 120/162.\n",
      "#  If you finished t6c, then this just a matter of playing with axis values.\n",
      "#sum_values = t6b_bucket_sums.sum(axis=0)\n",
      "#t6d_normed_bucket_sums = t6b_bucket_sums.div(sum_values)\n",
      "#print t6d_normed_bucket_sums\n",
      "\n",
      "\n",
      "#Once you have done this , uncomment the following line to a horizontal stacked bar chart\n",
      "#t6d_normed_bucket_sums.plot(kind='barh', stacked=True)\n",
      "\n",
      "\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "bins           (0, 1]  (1, 10]  (10, 100]  (100, 1000]  (1000, 10000]  \\\n",
        "cand_nm                                                                 \n",
        "Obama, Barack     493    40070     372280       153991          22284   \n",
        "Romney, Mitt       77     3681      31853        43357          26186   \n",
        "\n",
        "bins           (10000, 100000]  (100000, 1000000]  (1000000, 10000000]  \n",
        "cand_nm                                                                 \n",
        "Obama, Barack                2                  3                    4  \n",
        "Romney, Mitt                 1                NaN                  NaN  \n",
        "bins                 cand_nm      \n",
        "(0, 1]               Obama, Barack         318.24\n",
        "                     Romney, Mitt           77.00\n",
        "(1, 10]              Obama, Barack      337267.62\n",
        "                     Romney, Mitt        29819.66\n",
        "(10, 100]            Obama, Barack    20288981.41\n",
        "                     Romney, Mitt      1987783.76\n",
        "(100, 1000]          Obama, Barack    54798531.46\n",
        "                     Romney, Mitt     22363381.69\n",
        "(1000, 10000]        Obama, Barack    51753705.67\n",
        "                     Romney, Mitt     63942145.42\n",
        "(10000, 100000]      Obama, Barack       59100.00\n",
        "                     Romney, Mitt        12700.00\n",
        "(100000, 1000000]    Obama, Barack     1490683.08\n",
        "(1000000, 10000000]  Obama, Barack     7148839.76\n",
        "Name: contb_receipt_amt, dtype: float64\n"
       ]
      },
      {
       "ename": "ValueError",
       "evalue": "'axis' entry is out of bounds",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-121-2f979a3ceb6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mnewdf\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mdf6c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cand_nm'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'bins'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontb_receipt_amt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mnewdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnansum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt6b_bucket_sums\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/sumesh/ipython/anaconda/lib/python2.7/site-packages/numpy/lib/nanfunctions.pyc\u001b[0m in \u001b[0;36mnansum\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \"\"\"\n\u001b[1;32m    505\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_replace_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/sumesh/ipython/anaconda/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m         return _methods._sum(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 1716\u001b[0;31m                             out=out, keepdims=keepdims)\n\u001b[0m\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mproduct\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/sumesh/ipython/anaconda/lib/python2.7/site-packages/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: 'axis' entry is out of bounds"
       ]
      }
     ],
     "prompt_number": 121
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Task 7: Big Money in Politics\n",
      "------------------------------\n",
      "\n",
      "Using the tool of discretization, we were able to analyze how much people contributed in each bucket. While it showed some sense of imbalance, it did not show it clearly. Recently, the concept of income inequality is becoming a rallying cry among liberals. Let us see if there is any inequality in the contributions (spoiler alert: yes!). We can see if we find anything interesting, not by analyzing, total amount but by the amount contributed by top-X%.\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "#Task 7a: Write two functions: one for Obama and one for Romney that does the following:\n",
      "# Given a value of N (N can be 1, 2, 5, 10 etc), sort the contributions made to the candidate in decreasing order\n",
      "#  Then find how much contribution the top-N% made\n",
      "#  Then compute the fraction to the overall campaign collection\n",
      "# For example, if Obama collected 1 billion dollars and the top-1% gave 100 million then their contribution is 10%\n",
      "def t7a_contributions_by_top_N_pct_obama(N):\n",
      "    df7a = DataFrame(fec[fec.cand_nm.isin(['Obama, Barack'])].contb_receipt_amt.order(ascending=False))\n",
      "    top_N_no_of_contb = (N*df7a.contb_receipt_amt.count())/100\n",
      "    top_n_sum_of_contb = df7a.contb_receipt_amt[:top_N_no_of_contb].sum()\n",
      "    total_contb_obama = df7a.contb_receipt_amt.sum()\n",
      "    top_N_percent_contb = (top_n_sum_of_contb/total_contb_obama)*100\n",
      "    return top_N_percent_contb\n",
      "\n",
      "def t7a_contributions_by_top_N_pct_romney(N):\n",
      "    df7a = DataFrame(fec[fec.cand_nm.isin(['Romney, Mitt'])].contb_receipt_amt.order(ascending=False))\n",
      "    top_N_no_of_contb = (N*df7a.contb_receipt_amt.count())/100\n",
      "    top_n_sum_of_contb = df7a.contb_receipt_amt[:top_N_no_of_contb].sum()\n",
      "    total_contb_romney = df7a.contb_receipt_amt.sum()\n",
      "    top_N_percent_contb = (top_n_sum_of_contb/total_contb_romney)*100\n",
      "    return top_N_percent_contb\n",
      "\n",
      "\n",
      "for N in [1, 2, 5, 10, 20]:\n",
      "    print \"N=%s, Obama proportion=%s and Romney proportion = %s\" % (N, t7a_contributions_by_top_N_pct_obama(N), t7a_contributions_by_top_N_pct_romney(N))\n",
      "\n",
      "    \n",
      "#Task 7b: Now let us see who these people in 1% are\n",
      "# Compute the top-1% based on total contribution (ie. money they gave to Obama + Romney)\n",
      "# Now let us see some information about them.\n",
      "# For each of the folks in 1%, print the following:\n",
      "#    name, state, occupation, employer, total amount they gave to Obama, total amount they gave to Romney\n",
      "'''\n",
      "df7b = DataFrame(fec)\n",
      "df7b = df7b.sort(['contb_receipt_amt'],ascending=False)\n",
      "\n",
      "total_contribution = fec.contb_receipt_amt.sum()\n",
      "top_1_percent = total_contribution/100\n",
      "print top_1_percent\n",
      "top_1_no_of_contb = (1*df7a.contb_receipt_amt.count())/100\n",
      "#print top_1_no_of_contb\n",
      "#print df7b[:top_1_no_of_contb]\n",
      "\n",
      "df7b_new = df7b[:top_1_no_of_contb]\n",
      "#print df7b_new\n",
      "print df7b.groupby(['contbr_nm','cand_nm']).contb_receipt_amt.sum().order(ascending=False)\n",
      "\n",
      "#df7new = DataFrame(df7a[:top_1_no_of_contb])\n",
      "#print df7new\n",
      "#t7b_1pcters = DataFrame({'Name':df7new.cand_nm,'State':df7new.contbr_st,'Employer':df7new.contbr_employer})\n",
      "#print t7b_1pcters"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2242133.3477\n",
        "contbr_nm                             cand_nm      \n",
        "OBAMA VICTORY FUND 2012 - UNITEMIZED  Obama, Barack    8639522.84\n",
        "MURPHY, CYNTHIA C.                    Obama, Barack      35800.00\n",
        "DAVIS, STEPHEN JAMES                  Obama, Barack      30800.00\n",
        "HIEMSTRA, SHERRON                     Obama, Barack      20000.00\n",
        "PEROT, FRANCIS KINCAID                Obama, Barack      20000.00\n",
        "MAYORKAS, ALEJANDRO                   Obama, Barack      20000.00\n",
        "PUCK, GELILA                          Obama, Barack      20000.00\n",
        "BOULIND, JEANNETTE                    Obama, Barack      20000.00\n",
        "KLEIN, PATRICIA                       Obama, Barack      17750.00\n",
        "MEDORE, MARK                          Obama, Barack      15195.00\n",
        "ROLFE, RONALD                         Obama, Barack      15000.00\n",
        "ABRAMS, EDWIN                         Obama, Barack      15000.00\n",
        "TRAUB, JANET E.                       Obama, Barack      15000.00\n",
        "DENNE, CONSTANCE AYERS                Obama, Barack      15000.00\n",
        "ANDERSON, SALLY                       Obama, Barack      15000.00\n",
        "...\n",
        "ENGLANDER, EVELYN              Obama, Barack    3.00\n",
        "LIVAK, PAUL                    Obama, Barack    3.00\n",
        "GONZALEZ, FILIBERTO            Obama, Barack    3.00\n",
        "SHEPHERD, HENRY                Obama, Barack    3.00\n",
        "BILDNER, ROBERT L              Obama, Barack    3.00\n",
        "SLOAN, CHELSEA                 Romney, Mitt     3.00\n",
        "BOSTON, WILLIE JR.             Obama, Barack    3.00\n",
        "JOHNSON, BRENDA LAGRANGE AMB.  Romney, Mitt     3.00\n",
        "GREENBAUM MD, SCOTT DR.        Romney, Mitt     3.00\n",
        "SCOTT, MATTHEW                 Obama, Barack    3.00\n",
        "WHEELER, LINDA L               Obama, Barack    2.50\n",
        "WINTERSTEINER, PETER P.        Obama, Barack    2.00\n",
        "FOSS, MARNA                    Obama, Barack    2.00\n",
        "MICHAL, JUNE B                 Obama, Barack    1.00\n",
        "WILSON, LAURA                  Obama, Barack    0.08\n",
        "Name: contb_receipt_amt, Length: 251776, dtype: float64"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 144
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Task 8: Political Polarization in USA\n",
      "------------------------------------------\n",
      "\n",
      "It has been argued that political polarization has dramatically increased in USA in the last 10-15 years. While there are many ways to analyze the dataset for polarization, let us use some simple measures."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Task 8a: One way to measure polarity is to see how different some distribution are. \n",
      "# For both Obama and Romney, print the top-10 states based on their total AMOUNT of contribution\n",
      "# Do you see lot of common states? \n",
      "t8a_top_10_states_obama = None\n",
      "t8a_top_10_states_romney = None\n",
      "\n",
      "print t8a_top_10_states_obama\n",
      "print t8a_top_10_states_romney\n",
      "\n",
      "#Task 8b: For both Obama and Romney, print the top-10 occupation based on their total AMOUNT of contribution\n",
      "# Do you see lot of common occupation? \n",
      "t8b_top_10_occu_obama = None\n",
      "t8b_top_10_occu_romney = None\n",
      "\n",
      "print t8b_top_10_occu_obama\n",
      "print t8b_top_10_occu_romney\n",
      "\n",
      "\n",
      "\n",
      "#Task 8c: For both Obama and Romney, print the top-10 employers based on their total AMOUNT of contribution\n",
      "# Do you see lot of common employers? \n",
      "t8c_top_10_emp_obama = None\n",
      "t8c_top_10_emp_romney = None\n",
      "\n",
      "print t8c_top_10_emp_obama\n",
      "print t8c_top_10_emp_romney\n",
      "\n",
      "\n",
      "#Harder\n",
      "#Task 8d: Here is another way to compute polarization\n",
      "# Find the top-1000 contributors based on their TOTAL contribution (to both Obama and Romney)\n",
      "# For each of the top-1000 folks count the number of people who donated to both, to Obama only and to Romney only\n",
      "t8d_top_1000_both = None\n",
      "t8d_top_1000_BO_only = None\n",
      "t8d_top_1000_MR_only = None\n",
      "\n",
      "print t8d_top_1000_both, t8d_top_1000_BO_only, t8d_top_1000_MR_only\n",
      "\n",
      "#Harder:\n",
      "#Task 8e: Here is yet another way\n",
      "# For each state, compute what fraction of amount went to Obama and what fraction went to Romney\n",
      "# If there is no polarization, then both will get more or less equal amount. \n",
      "# If there is polarization, then the amount will skewed.\n",
      "# Let us use a very crude measure to compute polarization\n",
      "#    If X is what Obama got from a state and Y is what Romney got, compute the value of max(X,Y)/ (min(X,Y) + 1)\n",
      "# For each state compute this value and sort the results in a descending order. \n",
      "# Do you see any pattern?\n",
      "\n",
      "t8e_state_contr_ranked_by_polarity = None\n",
      "print t8e_state_contr_ranked_by_polarity\n",
      "\n",
      "\n",
      "#Harder:\n",
      "#Task 8f: Repeat the above analysis for occupation\n",
      "# However, instead of taking all occupations, let us only take the top-50 occupations based on TOTAL contributions made\n",
      "# For each occupation compute this value and sort the results in a descending order and displ\n",
      "# Do you see any pattern?\n",
      "\n",
      "t8f_occu_contr_ranked_by_polarity = None\n",
      "print t8f_occu_contr_ranked_by_polarity\n",
      "\n",
      "\n",
      "#Harder:\n",
      "#Task 8g: A known variable of polarization is based on where a person lives.\n",
      "# At the risk of too much generalization, liberals dominate cities while conservations dominate rural areas\n",
      "# Let us see if this holds in Texas.\n",
      "# Texas is a known solid red (i.e. conservative) state.\n",
      "# For each state in Texas, compute the polarity and order them by polarity.\n",
      "# Do you see any pattern?\n",
      "t8g_tx_city_contr_ranked_by_polarity = None\n",
      "print t8g_tx_city_contr_ranked_by_polarity\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "None\n",
        "None\n",
        "None\n",
        "None\n",
        "None\n",
        "None\n",
        "None None None\n",
        "None\n",
        "None\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 72
    }
   ],
   "metadata": {}
  }
 ]
}